Characteristics of Good
Data Structures & Algorithms
(kmitl) cs -departmentCh.02Outline
â€¢(Efficiency) Operations Counting
â€¢(Asympotic Analysis) ( ğ‘¶(ğ’ˆ(ğ’)), ğœ´(ğ’ˆ(ğ’)), ğœ½(ğ’ˆ(ğ’)))
Recap (Last Chapter)
â€¢Data Structures: Structures for keeping data
â€¢Algorithms: Steps for solving problem
â€¢Data Structures and Algorithms works together to solve problems.â€¢Good Characteristic : correctness and efficiency
â€¢(Efficiency) Benchmark
2Good Characteristics
â€¢Good characteristics of Data Structures 
& Algorithms
â€¢Correctness
â€¢Efficiency  
â€¢Time
â€¢Space
â€¢Efficiency (in space)
â€¢At the early age, we did care about 
space
â€¢After memory becomes cheap, we 
tends to care for speed more
â€¢In the age of Big Data, space 
becomes important again, in a whole 
new level.
â€¢We typically use the same tool for 
evaluate efficiency in speed and 
space.
â€¢Another key good characteristic is 
readability  â€¢Proof of correctness
â€¢Formal reasoning , a.k.a.
       Mathematical proof 
       - (Example of proving techniques)
       - Direct proof
       - Proof by contradiction
       - Proof by contraposition
       - Proof by Mathematical Induction
â€¢Empirical analysis
       -  Good for confirming theory
       -  Good enough if we donâ€™t 
           have theory?
       -  Your â€œtest casesâ€ should be
          complete enough.
       -  Beware of confirmation bias
3Correctness
4Recap
â€¢Characteristics of good Data Structures and Algorithms are 
correctness  and efficiency (and readability)
â€¢To proof the correctness, we can test it (empirical analysis), or we 
can formally (mathematically) proof it. 
â€¢Formal proof can guarantee the correctness.
â€¢Empirical analysis  need good test cases.
5â€¢Measuring Efficiency
Benchmark vs. Asymptotic Analysis
â€¢Benchmark
â€¢Similar to empirical test
â€¢Good for measuring end products.
â€¢Asymptotic analysis
â€¢Similar to Mathematical proof.
â€¢Concentrate on how time or space are increase as the size of input increase.
â€¢Compare the increasing trend to a familiar function.
6publicclassCountPiN {
staticboolean isPrime0(int n){
if(n==1) returnfalse;
if(n<=3) returntrue;
intm=n/2;
for(inti=2;i<=m;i++){
if(n%i==0)returnfalse;
}
returntrue;
}publicstaticvoidmain(String[] args){
   intcount=0;
intN=100;
for(intn=1;n<N;n++){
if(isPrime0(n)) count++;
}
System.out.println ("Pi("+N+")="+count);
}
}CountPiN.java
7â€¢ğ¶ğ‘œğ‘¢ğ‘›ğ‘¡ğ‘ƒğ‘–ğ‘ (ğ‘›) is a function that return number of prime (e.g. 
ğ¶ğ‘œğ‘¢ğ‘›ğ‘¡ğ‘ƒğ‘–ğ‘ 100 =25  Another two algorithms
static boolean isPrime1(int n) {
 if(n==1) return false;
 if(n<=3) return true;
 int m = (int) Math.sqrt (n);
 for(int i=2; i<=m; i++) {
  if(n%i==0) return false;
 }
 return true;
}
8Another two algorithms
static boolean isPrime2(int n) {
if(n==1) return false;
 if(n<=3) return true;
if((n%2==0)||(n%3==0)) return false;
int m = (int) Math.sqrt (n);
for(int i=5; i<=m; i+=6){
 if(n%i==0)return false;
if(n%(i+ 2)==0)return false;
}
return true;
}
9Modified main() method
publicstaticvoidbench_isPrime( L2_IsPrimeInterface obj) { 
intyour_cpu_factor = 1; /* increase by 10 times */
intN = 100;
intcount = 0;
for(N = 100_000; N<= 1_000_000 * your_cpu_factor; N+= 100_000 * your_cpu_factor) {
longstart = System.currentTimeMillis();
for(intn = 1; n < N; n++) {
if(obj.isPrime(n)) count++;
}
longtime = (System.currentTimeMillis() -start);
System.out.println(N + "\t"+ count + "\t"+ time);
}
}
10Recorded Results
N ğœ‹(ğ‘›)Times(milliseconds)
isPrime0 isPrime1 isPrime2
100,000 9,592 1,828 38 26
200,000 17,984 6,927 66 29
300,000 25,997 15,153 108 37
400,000 33,860 26,004 163 54
500,000 41,538 39,993 219 75
600,000 49,098 57,139 280 94
700,000 56,543 73,301 353 118
800,000 63,951 95,851 419 139
900,000 71,274 121,327 492 141
1,000,000 78,498 148,958 576 164
11Performance Graph
020,00040,00060,00080,000100,000120,000140,000160,000
0 200,000 400,000 600,000 800,000 1,000,000 1,200,000Time (milliseconds)
isPrime0 isPrime1 isPrime2
12Performance Graphs
020,00040,00060,00080,000100,000120,000140,000160,000
0 250,000 500,000 750,000 1,000,000isPrime0
0100200300400500600700
0 250,000 500,000 750,000 1,000,000isPrime1
isPrime2
13Observations
â€¢As N grows, the computing time is longer.
â€¢isPrime0 is noticeably slower, comparing to the other two
â€¢isPrime1 and isPrime2 are comparatively similar
â€¢We can safely say that isPrime0 is inferior to the other two
â€¢However, if our program only need to compute ğœ‹(ğ‘›) where n is 
relatively small, and only for a few times, any methods will do.
050,000100,000150,000200,000
0100200300400500600700
14Benchmark ing 
â€¢Good for measuring finished products.
â€¢We see them a lot in hardware testing. 
â€¢Key Properties
â€¢Relevance: Focus on vital features.
â€¢Representativeness: Accepted 
performance metrics.
â€¢Equity: Should be fairly compared.
â€¢Repeatability: Can be verified.
â€¢Cost -effectiveness: Should be 
economical.
â€¢Scalability: Should be able to test all 
range of system.
â€¢Transparency: Should be easy to 
understand.
15â€¢For comparing algorithms, using 
benchmark has its limitations . We need 
to be careful in these issues:
â€¢Must be done in the same 
environment, including hardware, 
operating system, selected computer 
language, etc.
â€¢Implementation details should be the 
same
â€¢May not reflect the real environment
â€¢May not reflect size of data, especially 
in the future. Why donâ€™t we use real world clock?
â€¢Real world clock measurement is possible but has many drawback
â€¢System dependency
â€¢Too complex (we have to  build the system.)
â€¢Too specific 
â€¢Ultimately, we want to know how long our program takes to do each 
operation
â€¢Use in design, how much resource we need 
â€¢Help us choose appropriate data structure  
16Estimating Time by Counting Operations
â€¢We will start by assuming that one command, one programming 
statement, takes a fixed amount of time.
â€¢If we have ğ‘š statement, it will take ğ‘˜ğ‘š milliseconds to follow them.
â€¢Linearly proportional to each other. 
â€¢For simplicity, we will assume that any statement takes the same 
amount time to compute. 
â€¢For example, x=3;  or Math.abs (-178) are consider to take the same amount of 
time to compute.
â€¢This might not be true, but good enough for our purpose.
â€¢Note that int m=n/2;  is count as 3 operations: declaration, assignment, and 
division.
â€¢Letâ€™s start counting
17isPrime0()
code operation count
1
2
3
4
5
6
7
8
9static boolean isPrime0(int n) {
 if(n==1) return false;
 if(n<=3)return true;
 int m=n/2;
 for(int i=2; i<=m; i++) {
if(n%i==0)return false;
 }
 return true;
  }1
1
3
2+ ((m-1)+1) +(m-1) = 2m+1
2(m-1)
1
total= ğŸ’ğ’ +ğŸ“
= ğŸğ’+ğŸ“
18isPrime 1()
code operation count
1
2
3
4
5
6
7
8
9static boolean isPrime1(int n) {
 if(n==1) return false;
 if(n<=3) return true;
 int m=(int)Math.sqrt (n);
 for(int i=2; i<=m; i++) {
if(n%i==0)return false;
 }
 return true;
  }1
1
4
2+ ((m-1)+1) +(m-1) = 2m+1
2(m-1)
1
total= ğŸ’ğ’ +ğŸ”
= ğŸ’ğ’+ğŸ”
19isPrime2()code operation count
1static boolean isPrime2(int n) {
2if(n==1) return false; 1
3if(n<=3) return true; 1
4if((n%2==0)||(n%3==0)) return false; 5
5int m=(int)Math.sqrt (n); 4
6for(int i=5; i<=m; i+=6) {2+(ğ’
ğŸ”+1)+ğ’
ğŸ” = 2ğ’
ğŸ”+3
7 if(n%i==0) return false;2ğ’
ğŸ”
8   if(n%(i+2)==0) return false;3ğ’
ğŸ”
9}
10return true; 1
11}
total= ğŸ•ğ’
ğŸ”+ğŸğŸ“
= ğŸ•ğ’
ğŸ”+ğŸğŸ“20Operation Function 
â€¢These are functions of number operations where n is the size of the 
input 
ğ‘“0ğ‘›= 2ğ‘›+5
ğ‘“1ğ‘›=4ğ‘›+6
ğ‘“2ğ‘›=7ğ‘›
6+15
Letâ€™s call them Operation Function
â€¢ Letâ€™s plot some graph
21Small input (n â‰¤20)
22Large Input
23Large Input w/o isPrime0
24Some Discussion
â€¢The result of statement counting is similar to our benchmark results.
â€¢isPrime0 grows at the same rate as the input.
â€¢isPrime1 and isPrime2 grows proportion to the square root of the input.
â€¢isPrime1 and isPrime2 are comparable, while isPrime0 is by far the slowest.
â€¢It is typically possible to count number of operations of algorithms.
â€¢(Remark) While the actual time depends on machines, number of 
operations does not.
â€¢Make it good for directly compare algorithms
â€¢It is also applicable to counting space.
â€¢Rather than remember the functions of all known algorithms, 
we will compare them to well -known functions using 
Asymptotic Analysis.ğ‘“0ğ‘›=2ğ‘›+5         ğ‘“1ğ‘›=4ğ‘›+6         ğ‘“2ğ‘›=7ğ‘›
6+15
25Recap (cont.)
â€¢Measuring efficiency can be done by benchmark and asymptotic 
analysis. 
â€¢Benchmark good for measuring end products
â€¢Asymptotic analysis measure growth rate of time or space comparing to 
the growth rate input.
â€¢Rather than measuring the time, we can count number of operations in 
algorithms
â€¢Number of operations are just an estimate number, which is good enough 
for our purpose.
â€¢If we know the function of operations of algorithms, we can compare them 
easily.
â€¢However,  we will not have to memorize the exact function of 
operations of each algorithm, we will use Asymptotic Analysis to 
compare them to well -known function.26Measurement by Growth Rate
â€¢Growth Rate = how much resource 
usage growth with respect to 
change of input 
â€¢Resource usage = number of 
instruction used 
â€¢input = size of data 
â€¢Emphasize long term trend 
27What? Why?
â€¢System Independent
â€¢The result can be used to predict 
behavior on any system
â€¢Focus on change of resource with 
respect to size of input
â€¢Can disregard small details
â€¢Simple to calculate
â€¢Applicable in real world Why should we care for large n?
28
Comparing Growth Rate
â€¢These are functions from size of input to number of computing 
operation of isPrime0, isPrime1, and isPrime2
â€¢We can say that the growth rates of  ğ‘“1ğ‘› and ğ‘“2ğ‘› are 
mathematically similar taking a limit as n approach infinity
lim
ğ‘›â†’âˆğ‘“1ğ‘›
ğ‘“2ğ‘›=lim
ğ‘›â†’âˆ4ğ‘›+6
7ğ‘›
6+15=24
7
â€¢These means that, ğ‘“1ğ‘› and ğ‘“2ğ‘› grows together to infinity. ğ‘“0ğ‘›=2ğ‘›+5         ğ‘“1ğ‘›=4ğ‘›+6         ğ‘“2ğ‘›=7ğ‘›
6+15
29Comparing Growth Rate
â€¢How about ğ‘“0ğ‘› comparing to ğ‘“1ğ‘›?
lim
ğ‘›â†’âˆğ‘“0ğ‘›
ğ‘“1ğ‘›=lim
ğ‘›â†’âˆ2ğ‘›+5
4ğ‘›+6=âˆ
â€¢This means that ğ‘“0ğ‘› is bigger than ğ‘“1ğ‘› if n is large enough.
â€¢Now, let compare ğ‘“2ğ‘› to ğ‘“0ğ‘›:
lim
ğ‘›â†’âˆğ‘“2ğ‘›
ğ‘“0ğ‘›=lim
ğ‘›â†’âˆ7ğ‘›
6+15
2ğ‘›+5=0
â€¢This means ğ‘“2ğ‘› is small comparing to ğ‘“0ğ‘› if n is large enough.
30Asymptotic Analysis  (ğ‘¶(ğ’ˆ(ğ’)), ğœ´(ğ’ˆ(ğ’)), ğœ½(ğ’ˆ(ğ’)))
â€¢We are to compare growth rates of functions, as their input 
increase (up to infinity), to another function. 
â€¢There are three asymptotic analysis commonly used in 
Computer Science: 
â€¢ğ‘“(ğ‘›)âˆˆğ‘¶(ğ’ˆ(ğ’)) read Big-Oof ğ‘“(ğ‘›) is ğ‘”ğ‘›, means that gğ‘› is an upper 
bound  of f(ğ‘›) or f(ğ‘›) grows asymptotically no faster than g (ğ’). 
â€¢Upper bound implies not worse than 
â€¢ğ‘“(ğ‘›)âˆˆğœ´(ğ’ˆ(ğ’)) read Big-Omega  of ğ‘“(ğ‘›) is ğ‘”ğ‘›, means that gğ‘› is a lower 
bound of  ğ‘“(ğ‘›) f(ğ‘›) grows asymptotically  faster than g (ğ’).
â€¢Lower bound implies no better than 
â€¢ğ‘“(ğ‘›)âˆˆğœ½(ğ’ˆ(ğ’)) read Big-Theta  of ğ‘“(ğ‘›) is ğ‘”ğ‘›, means that ğ‘“(ğ‘›) and gğ‘› 
are growing at that same rate or f(ğ’) grows asymptotically as fast as g(ğ’).
Note that ğ‘“(ğ‘›) and ğ‘”ğ‘› are defined on unbound subset of positive real 
number and ğ‘”ğ‘› is strictly positive for all large enough ğ‘›.
31Formal Definition
* images from diimdeep  GitHub32Simple g(n)
â€¢Rather than comparing to each other, we will compare each function 
with a simple function, for example 
ğ‘“0ğ‘›=2ğ‘›+5âˆˆğ‘‚(ğ‘›)
ğ‘“1ğ‘›=4ğ‘›+6âˆˆğ‘‚(ğ‘›)         
ğ‘“2ğ‘›=7ğ‘›
6+13âˆˆğ‘‚(ğ‘›)
â€¢So, we are saying that isPrime0 has ğ‘‚(ğ‘›) while isPrime1 and isPrime2 
has ğ‘‚ ğ‘›. 
â€¢Thus, we regards isPrime1 and isPrime2 as equal and superior to isPrime0
33Note on Big -O
â€¢In Computer Science, we often use only Big -O for asymptotic 
analysis.
â€¢However, people are expecting the smallest Big -O.
â€¢Although we say Big -O, we are expecting Big-Theta . 
â€¢To prevent side effect of big -o broad definition ( < âˆ ), though people 
normally imply Big -O in tight upper -bound manner.
â€¢For example, if you say ğ‘“1ğ‘›=4ğ‘›+6âˆˆğ‘‚(ğ‘›) is technically correct , but 
people will be expecting ğ‘‚(ğ‘›) and tends to think you are wrong .
â€¢Thus, to be the safe side, although we say Big -O, we should use Big -Theta 
whenever possible.
34Comparing Growth Rate (more example)
â€¢f(n) = 4 + 3n + 4n2 
â€¢g(n) = n2 
lim
ğ‘›â†’âˆ(4ğ‘›2+3ğ‘›+4
ğ‘›2 )=lim
ğ‘›â†’âˆ(4+3
ğ‘›+4
ğ‘›2)=4
â€¢Hence f(n) grows similar to  g(n)
â€¢Therefore f(n) = Î¸(n2) //  usually we determine whether it is theta by
    //  examining the code
â€¢(More example growth rate) f(n) = log(n) vs. g(n) = sqrt(n)?
35In practice â€“ determine the big O
(most frequently executed line) 
36function  partition(array, low, high) 
// Choose the last element as the pivot
pivot = array[high]
i = low - 1 // Index of smaller element
for j = low to high - 1 do
 if array[j] <= pivot then
 i = i + 1
  swap array[i] and array[j]
 end if
end for
// Place the pivot in its correct position
swap array[i + 1] and array[high] 
return i + 1 // Return the pivot index 
end function In practice â€“ determine the big O
(most frequently executed line) 
37function  hoare_partition(arr, low, high):  
    # Choose a pivot (e.g., the first element)
    pivot = arr[low]
    i = low - 1
    j = high + 1
    while True: # Move i to the right until an element >= pivot is found
 do
 i = i + 1
 while arr[i] < pivot # Move j to the left until an element <= pivot is found
 do
 j = j -1
 while arr[j] > pivot
 if i >= j: # If i and j have crossed, partitioning is done
 return j # or return i, either is fine
    swap(arr[i], arr[j]) # Swap the elements at i and jMore on O(n) vs. Î¸(n) 
38
Typical Big -O
Big-O Name
ğ‘‚(1) Constant
ğ‘‚(logğ‘›) Logarithmic 
ğ‘‚(ğ‘›) Linear
ğ‘‚(ğ‘› logğ‘›)Just ğ‘›logğ‘›
ğ‘‚(ğ‘›2) Quadratic
ğ‘‚(ğ‘›ğ‘˜) Polynomial
ğ‘‚(ğ‘ğ‘›) Exponential
ğ‘‚(ğ‘›!) Factorial
ğ‘‚(ğ‘›ğ‘›) Very bad!
* image from adrianmejia.com39P vs NP problems
â€¢If a problem is solvable with polynomial
time, ğ‘‚ğ‘›ğ‘˜, or less, we call them 
a P class problem .
â€¢NP-complete problem means a problem 
withno polynomial time solution. 
â€¢Although widely accept, there is 
no definite proof that Pâ‰ ğ‘ğ‘ƒ
NP is short for 
â€œnondeterministic polynomial timeâ€
40
Summary
â€¢To proof the correctness, we can test it (empirical analysis), or we can 
formally (mathematically) proof it. 
â€¢Empirical analysis need good test cases.
â€¢Formal proof can guarantee the correctness.
â€¢Measuring efficiency can be done by benchmark and asymptotic 
analysis. 
â€¢Benchmark good for measuring end products
â€¢Asymptotic analysis measure growth rate of time or space comparing to 
the growth rate input.
â€¢Asymptotic analysis measures computational complexity by comparing 
them asymptotically to well known functions.
â€¢There are several well known  functions that we are typically compare our 
function to.
41